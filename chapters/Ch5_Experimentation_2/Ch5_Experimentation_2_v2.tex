% =============================================================================
% CHAPITRE 5 : ÉTUDE 2 - DESIGN DE L'AGENT ET ILLUSION DE COMPRÉHENSION
% =============================================================================
% Structure alignée sur le modèle de thèse (sommaire + résumé + présentation)
% CONTENU INTÉGRAL CONSERVÉ - seule la structure est modifiée
% =============================================================================

\chapter{Étude 2 : Design de l'Agent et Illusion de Compréhension}
\label{ch:experimentation2}

% Sommaire de chapitre
\sommairechapitre

% =============================================================================
% SECTION 5.1 : RÉSUMÉ (NOUVELLE SECTION)
% =============================================================================

\section{Résumé}
\label{sec:exp2-resume}

Les agents pédagogiques alimentés par l'intelligence artificielle générative combinent désormais un discours fluide produit par les grands modèles de langage et une incarnation visuelle pouvant atteindre un réalisme saisissant. Dans ce contexte, cette expérimentation vise à examiner comment le design visuel d'un agent --- humanoïde ou abstrait --- influence la confiance, la persuasion perçue et la formation d'une illusion de compréhension chez de jeunes apprenants. Cent dix-neuf élèves de cinquième ont interagi avec un agent virtuel présentant un contenu sur l'Égypte antique, dans le cadre d'un plan inter-groupes manipulant l'apparence de l'agent (humanoïde vs. abstrait) tout en maintenant un contenu vocal identique. Nos résultats ne révèlent aucune différence significative entre les deux conditions concernant l'anthropomorphisme perçu, la confiance ou la persuasion. Cependant, indépendamment de la condition, les élèves manifestent une augmentation significative de leur auto-évaluation de compréhension après l'interaction avec l'agent, sans amélioration correspondante de leur performance objective au test de connaissances. Ce phénomène suggère que la fluidité conversationnelle générée par les LLM constitue désormais un signal de crédibilité prédominant, capable d'éclipser l'impact de l'incarnation visuelle. L'interaction avec un agent génératif, quelle que soit son apparence, semble induire une « illusion de maîtrise » métacognitive où les apprenants confondent la clarté de la présentation avec leur propre compétence.


% =============================================================================
% SECTION 5.2 : PRÉSENTATION DE L'EXPÉRIMENTATION (ancienne 5.1 Introduction)
% =============================================================================

\section{Présentation de l'expérimentation}
\label{sec:exp2-presentation}

Les trois expériences du chapitre précédent ont établi que l'interactivité orale avec un agent historique alimenté par l'IA générative suscite un intérêt supérieur à celui d'une présentation vidéo passive. Les élèves, du collège au lycée, déclarent un intérêt plus élevé lorsqu'ils peuvent questionner directement le personnage. Ce constat, s'il valide le potentiel motivationnel de ces dispositifs, ouvre une interrogation plus délicate. L'intérêt déclaré ne garantit pas l'apprentissage effectif. Un élève captivé par l'échange peut fort bien surestimer ce qu'il en retire. La fluidité même qui rend l'agent attrayant pourrait induire une confiance excessive dans sa propre compréhension. Le chapitre qui s'ouvre déplace donc l'analyse du versant motivationnel vers le versant métacognitif. Il ne s'agit plus de mesurer si les élèves \textit{aiment} interagir avec l'agent, mais d'examiner si cette interaction altère leur capacité à évaluer ce qu'ils \textit{savent réellement}.

La convergence des grands modèles de langage et des médias synthétiques permet désormais de créer des agents pédagogiques d'un réalisme saisissant. Ces technologies promettent un accompagnement personnalisé, capable de générer des dialogues adaptés en temps réel \citep{yan2024}. Leur efficacité dépend toutefois autant de la pertinence du discours que de la forme que prend l'incarnation. L'apparence visuelle de l'agent constitue un levier qui module la perception de l'apprenant, sa confiance et ses processus cognitifs. La recherche en interaction homme-machine a longuement exploré l'anthropomorphisme, cette tendance à projeter des traits humains sur des entités non humaines \citep{epley2007}. Le paradigme \textit{Computers as Social Actors} (CASA) a montré que des indices sociaux, même minimes, suffisent à déclencher l'application de scripts relationnels aux machines \citep{nass1994}, influençant la confiance initiale \citep{li2023}. Des travaux pionniers, conduits bien avant l'ère de l'IA générative moderne, ont néanmoins révélé que la quête du réalisme n'est pas toujours un atout. En créant des attentes comportementales, une apparence humaine rend saillante toute imperfection, générant potentiellement un malaise (\textit{Uncanny Valley}) et dégradant la crédibilité \citep{nowak2004, mcdonnell2012}. Ces travaux appartiennent cependant à un contexte technologique révolu. L'avènement des médias synthétiques, capables de générer des agents au réalisme frappant, a modifié l'équation. Il est désormais possible de créer des instructeurs virtuels photoréalistes --- des \textit{deepfakes} --- avec une fluidité et un réalisme qui brouillent la frontière entre réel et artificiel \citep{whittaker2020, xu2025a}.

C'est précisément cette nouvelle capacité d'incarner les LLM qui démultiplie les enjeux. D'un côté, des moteurs conversationnels produisent un discours parfaitement éloquent. De l'autre, des outils de génération vidéo offrent des visages humains animés de manière convaincante. La question devient alors : comment le design visuel d'un agent influence-t-il la perception de l'utilisateur lorsque la composante conversationnelle est devenue fluide ?

\subsection*{Anthropomorphisme et perception sociale}

L'anthropomorphisme visuel déclenche un processus cognitif spécifique. Les utilisateurs perçoivent d'abord un agent virtuel à travers son apparence, laquelle détermine ensuite leurs attributions de personnalité, d'émotions et de confiance \citep{mcdonnell2021}. Les premières recherches suggéraient une relation linéaire : plus une représentation informatique ressemble à un humain, plus elle suscite de réponses sociales. \citet{gong2008} a validé ce continuum empiriquement, montrant que des degrés croissants d'anthropomorphisme, d'une interface textuelle à une image humaine réelle, augmentaient proportionnellement les jugements sociaux, l'influence sociale et la compétence perçue. En résonance avec le cadre théorique posé au chapitre~\ref{ch:introduction}, le paradigme CASA explique ce mécanisme : les utilisateurs attribuent inconsciemment des traits humains aux agents informatiques et établissent avec eux des normes conversationnelles qui reflètent les interactions humaines, même lorsque ces agents n'affichent que des indices sociaux minimaux \citep{nass1994}. \citet{nass2000} décrivent ce phénomène comme une forme d'automatisme (\textit{mindlessness}), caractérisant la manière dont les utilisateurs appliquent des scripts sociaux aux machines, allant jusqu'à leur attribuer des traits de personnalité. Cette propension s'étend à des stéréotypes spécifiques, comme évaluer un ordinateur selon des biais de genre en fonction de sa voix \citep{nass1997}. Même lorsque les utilisateurs nient consciemment anthropomorphiser, ces scripts sociaux s'activent et les encouragent à interagir avec l'agent comme ils le feraient avec un interlocuteur humain \citep{kim2012}. Ces scripts activés augmentent la crédibilité perçue. En favorisant un sentiment de présence sociale \citep{biocca2003}, l'impression d'interagir avec un autre être social, les indices anthropomorphiques renforcent la confiance \citep{li2023}. La recherche sur les agents conversationnels incarnés s'est construite sur cette prémisse, visant un réalisme croissant pour maximiser l'engagement et la persuasion \citep{guadagno2007}.

L'intuition suggère qu'un agent plus réaliste devrait être mieux perçu. La recherche empirique tend à démontrer le contraire. Des études ont mis en évidence un effet contre-intuitif : des agents à l'apparence moins humaine sont jugés plus crédibles et socialement attractifs que leurs équivalents plus anthropomorphes \citep{nowak2004}. Des interfaces informatiques minimalistes exercent une influence supérieure sur la prise de décision par rapport à des représentations humaines \citep{bengtsson1999}. L'explication réside dans la théorie de la violation des attentes. Plus un agent a l'air humain, plus l'utilisateur s'attend à ce qu'il se comporte de manière humaine \citep{groom2009}. Or les agents virtuels actuels échouent souvent à satisfaire ces attentes sur le plan comportemental, même lorsque leur apparence est convaincante. Cette violation génère une rupture dans la confiance \citep{burgoon2015}. La gestion des attentes se complexifie lorsque plusieurs canaux de communication se combinent. L'alignement entre les modalités --- apparence, voix, gestes, expressions émotionnelles --- devient un enjeu critique. La compétence de l'agent dans la tâche peut prendre le pas sur son apparence. Une discordance entre une apparence humaine et une voix robotique peut ne pas affecter la confiance si l'agent fournit des informations précises et fiables dans ses guidages \citep{alimardani2024}. Le contexte d'interaction détermine également l'acceptation par l'utilisateur. Une expressivité émotionnelle positive dans un contexte social peut sembler inappropriée et nuire à la confiance dans une tâche critique, où la neutralité est attendue \citep{torre2019}. Une tension existe entre engagement et objectifs informationnels. Des animations riches et des gestes expressifs rendent l'agent plus apprécié, mais ces caractéristiques peuvent distraire visuellement l'utilisateur et détourner des ressources cognitives, sapant l'efficacité persuasive du message \citep{parmar2022}.

Au-delà de l'apparence visuelle, la voix détermine la perception des agents. La voix humaine sert d'indicateur de la présence d'un esprit, capable d'humaniser un interlocuteur, tandis que la communication textuelle peut déshumaniser \citep{schroeder2016}. La qualité prosodique de la voix s'avère plus déterminante que l'incarnation visuelle pour la perception du naturel. Un agent réaliste avec une prosodie inadéquate sera jugé moins naturel qu'un agent désincarné avec une prosodie correcte \citep{ehret2021}. L'« effet de la voix » prédisait la supériorité de la voix humaine sur la voix synthétique pour l'apprentissage. Les avancées technologiques ont remis en cause cette hypothèse. Les voix synthétiques modernes de haute qualité produisent des résultats d'apprentissage équivalents, voire supérieurs, à ceux obtenus avec une voix humaine, particulièrement en termes de transfert de connaissances \citep{craig2017}. La voix humaine conserve néanmoins un avantage pour établir la confiance et la crédibilité perçue, même si cet avantage ne se traduit pas toujours en meilleure performance d'apprentissage \citep{craig2019, chiou2020}. La présence sociale induite par une voix humaine semble médiatiser cette crédibilité accrue, un effet qui opère indépendamment de l'expertise déclarée de l'agent \citep{kim2022}.

L'intégration d'une représentation visuelle de l'instructeur --- son incarnation --- produit des résultats contradictoires dans la littérature. L'effet d'incarnation suggère que des agents animés utilisant des gestes et des expressions faciales améliorent l'apprentissage, en activant chez l'apprenant un sentiment de partenariat social qui favorise un traitement cognitif plus profond \citep{mayer2012}. Une littérature substantielle souligne cependant les coûts cognitifs de cette présence. La présence visuelle d'un instructeur, particulièrement d'un humain réel, agit comme un aimant attentionnel. Des études d'oculométrie ont démontré que les apprenants passent un temps considérable à regarder le visage de l'instructeur au détriment du contenu pédagogique affiché à l'écran \citep{wang2017}. Cette distraction visuelle crée une dissociation frappante entre perception et performance : les apprenants apprécient davantage la leçon, la jugent plus intéressante et ont l'impression de mieux apprendre, mais leurs résultats de compréhension objective diminuent \citep{wilson2018}. Cette dynamique se résume par l'expression « plus de regard, mais moins d'apprentissage ». Elle est plus prononcée avec des instructeurs très réalistes, qui s'avèrent moins efficaces que des personnages de type cartoon, car leur saillance sociale impose un coût attentionnel supérieur \citep{li2024}.

\subsection*{L'illusion de compréhension comme risque métacognitif}

La psychologie éducative a établi qu'évaluer sa propre compréhension est un processus intrinsèquement faillible \citep{flavell1979}. Cette difficulté d'auto-évaluation conduit fréquemment les apprenants à croire qu'ils ont compris un contenu alors même qu'ils échouent à détecter des contradictions évidentes \citep{glenberg1982}. Ce phénomène est particulièrement exacerbé avec la technologie : \citet{salomon1984} a démontré que lorsqu'un média est perçu comme « facile » à traiter, les apprenants réduisent leur investissement mental (\textit{Amount of Invested Mental Effort}), ce qui dégrade la qualité de l'apprentissage. L'arrivée de l'IA générative ramène ces mécanismes au premier plan.

L'illusion de compréhension, définie au chapitre~\ref{ch:introduction} (section~\ref{sec:intro_problematique}), constitue ici le cœur de notre investigation. Ce biais métacognitif désigne la tendance d'un individu à surestimer la profondeur de ses propres connaissances sur un système causal jusqu'à ce qu'il soit contraint de produire une explication détaillée de celui-ci \citep{rozenblit2002}. Cette illusion peut être déclenchée par des heuristiques de traitement. Une information facile à traiter est plus susceptible d'être jugée vraie, indépendamment de son contenu \citep{reber1999}. L'effet de vérité illusoire décrit comment la simple répétition d'une déclaration, même fausse, augmente sa crédibilité perçue en accroissant sa familiarité \citep{fazio2015}. Observer la démonstration d'une tâche par un instructeur --- comme un pas de danse ou un tour de magie --- peut générer une « illusion d'acquisition de compétence », où l'observateur confond la fluidité du traitement visuel (le fait que l'action paraît simple) avec sa propre capacité à l'exécuter \citep{kardas2018}. Ces illusions sont d'autant plus prononcées qu'elles s'inscrivent dans des déficits métacognitifs plus larges. L'effet Dunning-Kruger souligne un « double fardeau » : les individus les moins compétents sont non seulement ceux qui performent le moins bien, mais ils manquent également des compétences métacognitives nécessaires pour reconnaître leur propre incompétence et calibrer leur jugement \citep{kruger1999}.

Les LLM possèdent des caractéristiques techniques qui risquent d'amplifier spécifiquement l'illusion de compréhension métacognitive. Leur capacité à générer un discours instantané, parfaitement structuré et linguistiquement fluide maximise la fluidité de traitement pour l'utilisateur. Cette fluidité peut conduire les apprenants à accepter facilement des explications scientifiquement erronées lorsqu'elles sont intuitives et présentées de manière fluide \citep{kulgemeyer2023}. Dans des scénarios réels, les LLM sont sujets aux « hallucinations » --- la génération d'informations plausibles mais incorrectes présentées avec une grande confiance \citep{shanahan2024}. Si les apprenants réduisent leur vigilance critique face à un contenu correct en raison de sa fluidité, ils deviennent vulnérables à accepter des informations erronées présentées avec la même assurance.

\subsection*{Objectifs de l'étude}

Une grande partie des travaux sur le réalisme des agents, parfois contradictoires, a été conduite avec des technologies dont le réalisme visuel et les capacités conversationnelles étaient bien en deçà des standards actuels \citep{bengtsson1999, nowak2004}. La question se pose de savoir comment ces dynamiques évoluent lorsqu'un agent hyperréaliste devient l'interface d'un discours fluide généré par un LLM. La présente étude vise à combler cette lacune en examinant spécifiquement comment le design visuel d'un agent, comparant une représentation humanoïde à une représentation abstraite, influence l'anthropomorphisme perçu, la confiance envers l'agent, la persuasion perçue, et ultimement la formation de l'illusion de compréhension dans un contexte d'apprentissage avec de jeunes élèves.

Ce chapitre présente d'abord la méthodologie employée, détaillant les conditions expérimentales, l'implémentation logicielle, les participants, la procédure et les hypothèses formulées. Les résultats sont ensuite exposés, avant d'être discutés à la lumière des implications théoriques et pratiques pour la conception d'agents pédagogiques à l'ère de l'IA générative.


% =============================================================================
% SECTION 5.3 : MÉTHODOLOGIE (ancienne 5.2)
% =============================================================================

\section{Méthodologie}
\label{sec:exp2-methodologie}

\subsection{Conditions Expérimentales}
\label{subsec:exp2-conditions}

L'étude a employé un design expérimental inter-groupes avec l'apparence de l'agent comme variable indépendante. Chaque classe participante a été assignée à l'une des deux conditions expérimentales. Deux designs d'agents distincts ont été créés pour manipuler le niveau d'anthropomorphisme tout en maintenant un contenu informationnel et des caractéristiques vocales identiques.

\textbf{Condition Agent Humanoïde.} Dans cette condition (voir Figure~\ref{fig:exp2_humanoid_agent}), l'agent virtuel apparaissait comme un professionnel masculin d'âge moyen s'adressant directement à la caméra, avec des mouvements naturels de la tête et des expressions faciales synchronisées avec la parole. Cette représentation visuelle a été générée à l'aide de HeyGen\footnote{HeyGen: https://www.heygen.com}, une plateforme de génération vidéo basée sur l'IA, et présentait un environnement de bureau neutre avec une tenue formelle. Les expressions faciales et les mouvements ont été conçus pour paraître naturels mais contenus, évitant toute théâtralité distrayante.

\textbf{Condition Agent Abstrait.} Dans cette condition (voir Figure~\ref{fig:exp2_abstract_agent}), l'agent virtuel était représenté par une visualisation audio-réactive non anthropomorphique. L'interface consistait en un cercle blanc pulsant central dont la taille variait avec l'amplitude audio, entouré de 48 barres radiales réagissant à des bandes de fréquences spécifiques du spectre vocal.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{images/ch5/human.jpg}
    \caption{L'agent humanoïde tel que présenté aux participants, avec une apparence humaine réaliste et des expressions faciales.}
    \label{fig:exp2_humanoid_agent}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{images/ch5/abstract.png}
    \caption{L'agent abstrait avec sa visualisation en onde sonore.}
    \label{fig:exp2_abstract_agent}
\end{figure}


\subsection{Implémentation Logicielle}
\label{subsec:exp2-implementation}

Nous avons développé Merlin, une application personnalisée pour présenter les stimuli et gérer la session expérimentale, en utilisant le framework Electron\footnote{Electron: https://www.electronjs.org} (v28.0.0). L'architecture de l'application sépare le contrôle expérimental de la présentation des stimuli.

\textbf{Architecture Technique.} Le système se compose de trois composants principaux gérés par le modèle multi-processus d'Electron. Le \textit{Processus Principal} coordonne le cycle de vie de l'application, la création des fenêtres et la communication inter-processus. L'\textit{Interface Opérateur} permet au chercheur de sélectionner les conditions expérimentales, de déclencher les réponses de l'agent et de contrôler les paramètres en temps réel (volume audio, vitesse de transition, mode plein écran). L'interface inclut un journal d'activité avec horodatage et des contrôles de préchargement des médias. L'\textit{Interface Participant} affiche l'agent virtuel sur un écran visible par toute la classe. Cette fenêtre a été configurée avec une résolution et des paramètres d'affichage cohérents à travers toutes les sessions expérimentales pour assurer des conditions de visualisation standardisées. Les Figures~\ref{fig:exp2_interface_humanoid} et~\ref{fig:exp2_interface_abstract} illustrent le dispositif expérimental complet, montrant les interfaces destinées aux participants pour chaque condition ainsi que le panneau de contrôle de l'opérateur.

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{images/ch5/interface.png}
    \caption{Interface de l'agent humanoïde avec le panneau de contrôle de l'opérateur.}
    \label{fig:exp2_interface_humanoid}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{images/ch5/interface_abstract.png}
    \caption{Interface de l'agent abstrait avec le panneau de contrôle de l'opérateur.}
    \label{fig:exp2_interface_abstract}
\end{figure}

\textbf{Gestion des Médias et Synchronisation.} Pour la condition agent humanoïde, des séquences vidéo ont été créées pour différents états d'interaction (animation d'attente, message de bienvenue, réponses aux questions, message de clôture). Le système implémente un double buffering pour des transitions fluides entre les séquences vidéo, avec des fondus enchaînés CSS assurant une lecture sans coupure. Pour la condition agent abstrait, la visualisation audio-réactive a été implémentée en utilisant l'API HTML5 Canvas et l'API Web Audio pour l'analyse fréquentielle en temps réel. L'animation visuelle était synchronisée avec les réponses audio par une analyse FFT (Fast Fourier Transform) réalisée sur le signal vocal.

\textbf{Synthèse Vocale et Standardisation du Contenu.} Les deux conditions utilisaient un contenu vocal synthétique identique généré par ElevenLabs\footnote{ElevenLabs: https://elevenlabs.io} avec des paramètres cohérents. La voix a été sélectionnée pour sa clarté, son ton formel et ses caractéristiques neutres, évitant les accents régionaux marqués. Le contenu audio pour la condition abstraite a été extrait des vidéos de la condition humanoïde, assurant un contenu informationnel équivalent, un débit de parole, une intonation et une prosodie identiques à travers les conditions. Cette standardisation garantit que les différences observées entre les conditions reflètent le design visuel plutôt que les variations vocales.


\subsection{Participants}
\label{subsec:exp2-participants}

Cent dix-neuf élèves de classes de cinquième ($N$ = 119 ; âge moyen = 11,77 ans, $ET$ = 0,49) d'un collège privé sous contrat ont participé à l'étude. La distribution par sexe était de 76 garçons (63,9\%) et 43 filles (36,1\%). Les participants ont été recrutés après l'obtention du consentement éclairé des représentants légaux et de l'assentiment des élèves. L'activité en classe sur la momification dans l'Égypte antique a été intégrée au programme régulier d'histoire et conduite pendant les heures de cours. La participation au volet recherche (complétion des questionnaires et fourniture de données pour l'analyse) était volontaire. Tous les élèves ont participé à l'activité en classe, mais seuls ceux qui ont consenti ont contribué leurs données à cette étude. Quatre classes ont été assignées aléatoirement à l'une des deux conditions expérimentales : la condition « agent humanoïde » ($n$ = 60) ou la condition « agent abstrait » ($n$ = 59).


\subsection{Procédure et Mesures}
\label{subsec:exp2-procedure}

L'expérience a été conduite dans une salle de classe standard équipée d'un ordinateur portable exécutant l'application Merlin, d'un vidéoprojecteur pour afficher l'agent, et d'un système sonore pour diffuser l'audio. Un microphone externe mobile a été utilisé par les élèves désignés comme porte-paroles pendant la phase d'interaction.

Le contenu pédagogique portait sur la momification dans l'Égypte antique, un sujet du programme de sixième que les participants avaient étudié l'année précédente. L'expérience s'est déroulée en une seule session d'environ 60 minutes par classe, pendant les heures de cours régulières. L'anonymat des données a été assuré en attribuant un code alphanumérique unique à chaque élève (par exemple, A01, A02), reporté sur tous les documents collectés.

\textbf{Procédure Pré-expérimentale.} La session a débuté par une brève présentation sur la momification dans l'Égypte antique. Les informations démographiques de base (âge et sexe biologique) ont été collectées à ce stade. Les élèves ont ensuite complété individuellement les trois premières phases du protocole adapté d'Illusion de Profondeur Explicative (IOED) \citep{rozenblit2002} (détail en Annexe~\ref{annexe:ioed}). Le concept cible pour toutes les mesures IOED était : \textit{« Comment les anciens Égyptiens s'y prenaient-ils pour transformer un mort en momie ? »}

Les trois phases initiales étaient les suivantes. La \textit{Phase 1 (Auto-évaluation initiale [T1])} demandait aux élèves d'évaluer leur niveau de connaissance perçu sur une échelle de Likert en 7 points allant de 1 (« Je ne connais rien du tout ») à 7 (« Je connais très bien le sujet »). La \textit{Phase 2 (Production d'explications)} demandait aux élèves de rédiger une explication du processus de momification dans leurs propres mots, dans un espace limité. Il leur était demandé d'expliquer le processus comme s'ils l'enseignaient à un ami ou à un élève plus jeune non familier avec le sujet, en considérant : les étapes séquentielles, les outils ou matériaux utilisés, la durée du processus, son objectif, et les individus responsables de son exécution. La \textit{Phase 3 (Réévaluation intermédiaire [T2])} demandait aux élèves, après avoir produit leur explication, de réévaluer leur niveau de connaissance en utilisant la même échelle en 7 points. Ces mesures ont établi une ligne de base de la compréhension perçue et de la capacité explicative des élèves avant l'interaction avec l'agent.

\textbf{Procédure Expérimentale et Tâches.} Suite à la phase de pré-test individuelle, les élèves ont été organisés en petits groupes de travail de 4 à 5 membres. Chaque groupe a reçu une liste de six questions prédéfinies portant sur des aspects périphériques des pratiques et croyances funéraires de l'Égypte antique. Ces sujets étaient intentionnellement distincts du processus central de momification évalué dans le test de connaissances post-interaction (détaillé dans la section suivante). Cette approche empêchait l'agent de fournir des réponses directes à l'évaluation, nous permettant de mesurer si la confiance établie pendant l'interaction se généraliserait au sujet principal :

\begin{enumerate}
    \item « Quels étaient les dieux les plus importants pour les Égyptiens, et quel était leur rôle dans la protection et le guidage des morts dans leur voyage vers l'au-delà ? »
    \item « Au-delà de la protection du corps, quel était le rôle symbolique et religieux du sarcophage dans les rituels funéraires ? »
    \item « Pourquoi la mort d'un pharaon était-elle un événement si important et spectaculaire pour tout le royaume d'Égypte ? »
    \item « À quoi servaient les objets du quotidien et la nourriture placés dans les tombes, et qu'est-ce que cela nous apprend sur leur vision de l'au-delà ? »
    \item « Quelle était la fonction des pyramides pour le pharaon, et pour quelles raisons les Égyptiens ont-ils ensuite choisi de construire des tombes cachées dans la Vallée des Rois ? »
    \item « En quoi consistait le rituel de l'« Ouverture de la Bouche », et pourquoi était-il considéré comme essentiel pour la momie ? »
\end{enumerate}

Les réponses de l'agent à ces questions ont été générées à l'aide de ChatGPT-5\footnote{ChatGPT-5, développé par OpenAI: https://openai.com/chatgpt} puis validées par un enseignant d'histoire-géographie pour leur exactitude historique et leur adéquation pédagogique à l'âge des participants. Ces réponses étaient identiques dans les deux conditions expérimentales.

Les groupes avaient pour consigne de discuter collectivement et de sélectionner les deux questions qu'ils considéraient comme les plus importantes ou intéressantes. Au sein de chaque groupe, un élève était désigné comme porte-parole pour la phase d'interaction suivante. Cette phase de sélection collaborative durait environ 7 minutes.

Avant l'interaction, les élèves ont été explicitement informés qu'ils interagiraient avec un personnage virtuel alimenté par l'intelligence artificielle. Cette transparence était essentielle pour notre design expérimental pour trois raisons. Premièrement, la génération actuelle d'élèves a grandi avec des assistants vocaux et des chatbots ; présenter le personnage comme un être humain réel aurait créé une dissonance cognitive avec ces représentations préexistantes. Deuxièmement, si les participants avaient été amenés à croire qu'ils interagissaient avec un expert humain, leurs réponses auraient reflété des jugements sur « un humain avec une apparence inhabituelle » plutôt que des perceptions d'un agent IA, invalidant ainsi notre manipulation centrale du design de l'agent. Troisièmement, la tromperie aurait été fragile dans un contexte de classe, où un seul élève reconnaissant la nature artificielle de l'interaction aurait pu compromettre l'ensemble du protocole. En assurant la transparence, nous avons isolé l'effet du design visuel sur l'interaction humain-IA des croyances confondantes sur la nature de l'agent. Cette transparence a également satisfait aux exigences éthiques concernant la participation éclairée. L'agent était projeté sur un écran central visible par tous les élèves. La Figure~\ref{fig:exp2_classroom_setup} montre le dispositif expérimental pendant une session d'interaction typique.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{images/ch5/classroom_setup.jpg}
    \caption{Dispositif expérimental dans la salle de classe montrant l'agent projeté sur l'écran pendant la phase d'interaction.}
    \label{fig:exp2_classroom_setup}
\end{figure}

Pendant l'interaction, les porte-paroles désignés de chaque groupe posaient à tour de rôle leur question sélectionnée oralement en utilisant un microphone mobile. L'agent fournissait des réponses orales préprogrammées dont le contenu était identique à travers les deux conditions expérimentales. Cette phase d'interaction durait environ 25 minutes, permettant à chaque groupe de poser sa question et d'entendre la réponse de l'agent.

\textbf{Procédure Post-expérimentale.} Immédiatement après la phase d'interaction avec l'agent, les élèves ont complété individuellement et silencieusement les mesures restantes dans leur livret papier. Cette phase post-expérimentale a évalué l'évolution de leur compréhension et leurs perceptions de l'agent.

Les élèves ont complété la phase finale du protocole IOED \citep{rozenblit2002} (Phase 4 : Réévaluation finale post-interaction [T3]), évaluant une dernière fois leur connaissance perçue du même concept — « Comment les anciens Égyptiens s'y prenaient-ils pour transformer un mort en momie ? » — sur une échelle de Likert en 7 points allant de 1 (« Je ne connais rien du tout ») à 7 (« Je connais très bien le sujet »).

Le livret contenait ensuite une série d'échelles standardisées pour collecter les perceptions des élèves concernant l'agent. L'\textit{Anthropomorphisme Perçu de l'Agent} a été mesuré à l'aide d'une adaptation française de la sous-échelle « Anthropomorphism » du Godspeed Questionnaire Series \citep{bartneck2009}, comprenant 5 items évalués sur des échelles différentielles sémantiques en 5 points (voir Annexe~\ref{annexe:godspeed}). La \textit{Confiance Multidimensionnelle} a été évaluée via une adaptation française du Multi-Dimensional Measure of Trust (MDMT) de \citet{malle2021}, composée de 16 items sur des échelles de Likert en 7 points (voir Annexe~\ref{annexe:mdmt}). La \textit{Persuasion Perçue} a été mesurée avec une adaptation française de l'échelle de \citet{thomas2019}, consistant en 9 items sur des échelles de Likert en 7 points (voir Annexe~\ref{annexe:persuasion}).

Finalement, un test de connaissances co-conçu avec un enseignant d'histoire-géographie a été administré pour évaluer la compréhension des élèves du processus de momification. Contrairement aux aspects périphériques des pratiques funéraires égyptiennes abordés par les réponses de l'agent, ce test portait sur la procédure centrale de momification elle-même : le processus technique, les matériaux utilisés et les raisons sous-jacentes de la momification. Le test comprenait trois questions à choix multiples et deux questions à réponse courte nécessitant des explications écrites de deux à trois phrases (voir Annexe~\ref{annexe:test-connaissances} pour les items complets). Cette conception garantissait que le test mesurait la compréhension réelle de la momification plutôt que la simple rétention des déclarations de l'agent.

La complétion de tous ces questionnaires post-interaction a duré environ 20 minutes. Durant les dernières minutes de la session, les élèves ont été informés d'un suivi à venir ; une session de débriefing dédiée de 30 à 40 minutes a ensuite été conduite une semaine plus tard dans toutes les classes participantes pour discuter de la momification égyptienne, clarifier les informations et répondre aux questions. De plus, la session a expliqué les objectifs de recherche de manière adaptée à l'âge des participants, incluant le concept d'illusion de compréhension et la pensée critique envers les sources d'information basées sur l'IA.


\subsection{Hypothèses}
\label{subsec:exp2-hypotheses}

La convergence des technologies génératives permet désormais de combiner une apparence hyperréaliste avec la fluidité conversationnelle d'un LLM. Cette configuration invite à réexaminer les conclusions des travaux antérieurs sur l'anthropomorphisme. Conduits dans un contexte technologique différent, ces études ont observé qu'un réalisme élevé pouvait saper la crédibilité en créant des attentes comportementales non satisfaites \citep{bengtsson1999, nowak2004}. La question est donc de savoir comment le design visuel d'un agent influence la perception de l'utilisateur lorsque la composante conversationnelle est devenue fluide. En nous appuyant sur le paradigme CASA \citep{nass1994,nass2000}, nous avons formulé les hypothèses suivantes :

\textbf{H1 : L'agent humanoïde suscitera une confiance plus élevée que l'agent abstrait.} L'apparence humaine est un puissant déclencheur de scripts sociaux, des mécanismes automatiques que les utilisateurs appliquent inconsciemment aux interfaces \citep{nass2000}. Cette prédisposition sociale est particulièrement marquée chez les jeunes adolescents, qui évaluent un agent pédagogique davantage sur ses qualités relationnelles, telles que sa sociabilité et la confiance qu'il inspire, que sur des critères de performance technique privilégiés par les adolescents plus âgés \citep{Nguyen2022}. Jusqu'à récemment, l'exploitation de ce levier était entravée par les imperfections visuelles des agents, créant un risque de rejet \citep{xu2025a}. Cependant, les avancées technologiques permettent désormais de générer des agents hyperréalistes dont la perception subjective est comparable à celle d'instructeurs humains \citep{lim2024}, et dont l'attrait est renforcé par l'association avec des figures familières \citep{tan2025}. Par conséquent, nous prédisons que l'agent humanoïde sera perçu comme une source plus digne de confiance. Toutefois, cette hypothèse est limitée à la confiance subjective. La littérature a en effet établi une dissociation entre la perception d'un agent et la confiance comportementale, cette dernière étant davantage influencée par la compétence perçue de l'agent que par son apparence \citep{kulms2019,alimardani2024}.

\textbf{H2 : L'agent humanoïde sera perçu comme plus persuasif, conduisant les élèves à accepter ses déclarations comme vraies plus facilement.} La persuasion est en partie déterminée par la crédibilité attribuée à la source. La fluidité et le ton autoritaire du discours, caractéristiques des LLMs, tendent à augmenter cette crédibilité perçue et à réduire la vigilance critique, même chez les apprenants avertis du risque d'erreur \citep{church2024,shekar2024}. Nous émettons l'hypothèse que l'incarnation humanoïde amplifiera cet effet. En activant les schémas sociaux, l'agent humanoïde devrait être perçu comme une source plus crédible, ce qui conduira les élèves à accepter ses déclarations avec moins de distance critique que celles de l'agent abstrait. Cette prédiction est formulée malgré des travaux plus anciens montrant que des agents moins anthropomorphes pouvaient être plus influents, suggérant que les capacités des technologies actuelles ont pu modifier cette dynamique \citep{bengtsson1999,zanbaka2006,gong2008}.

\textbf{H3 : L'agent humanoïde induira une illusion de compréhension plus forte que l'agent abstrait.} L'illusion de compréhension, qui correspond à une surestimation de ses propres connaissances \citep{rozenblit2002}, peut être déclenchée par des heuristiques de traitement. Dans nos deux conditions, le discours généré par le LLM, optimisé pour la clarté \citep{shanahan2024}, crée un risque cognitif de base en favorisant la fluidité du message : une information facile à traiter est plus susceptible d'être jugée vraie, indépendamment de son contenu \citep{reber1999}. Nous prédisons que l'agent humanoïde amplifiera ce risque en ajoutant la fluence de la source. Ce phénomène décrit comment une présentation perçue comme claire et confiante peut augmenter la confiance des apprenants dans leur propre maîtrise, indépendamment de leur performance objective \citep{toftness2018}. La présence visuelle d'un instructeur réaliste, agissant comme un \textit{seductive detail}, est connue pour maximiser cet effet en améliorant l'expérience subjective de l'apprenant, parfois au détriment de l'apprentissage \citep{wilson2018, li2024}. Ce mécanisme d'amplification est particulièrement pertinent pour les jeunes apprenants, qui affichent initialement une surconfiance envers le contenu généré par l'IA \citep{solyst2024} et dont les modèles mentaux de la technologie, encore en développement, les rendent plus dépendants des indices de surface pour évaluer la crédibilité \citep{andries2023}. Nous prédisons donc que l'agent humanoïde induira une illusion de compréhension significativement plus forte que l'agent abstrait.



% =============================================================================
% SECTION 5.4 : RÉSULTATS (ancienne 5.3)
% =============================================================================

\section{Résultats}
\label{sec:exp2-resultats}

\subsection{Analyses Préliminaires}
\label{subsec:exp2-analyses-preliminaires}

\textbf{Caractéristiques Démographiques des Participants.} Les caractéristiques démographiques ont été examinées à travers les conditions expérimentales. La condition agent humanoïde incluait 60 participants (âge moyen = 11,65 ans, $ET$ = 0,52), tandis que la condition agent abstrait incluait 59 participants (âge moyen = 11,90 ans, $ET$ = 0,44). La distribution par sexe était de 40 garçons (66,7\%) et 20 filles (33,3\%) dans la condition humanoïde, et 36 garçons (61,0\%) et 23 filles (39,0\%) dans la condition abstraite. Aucun participant n'a été exclu sur la base des critères prédéfinis.

\textbf{Test des Hypothèses Statistiques.} Avant de conduire les analyses paramétriques, les hypothèses de normalité et d'homogénéité des variances ont été évaluées. Le test de Levene pour l'égalité des variances a indiqué une homogénéité des variances à travers les conditions pour les scores de compréhension auto-évaluée à tous les points temporels (T1 : Initial, T2 : Post-Explication, T3 : Post-Interaction) ($F$(1, 117) = 2,294, $p$ = ,133 ; $F$(1, 117) = 1,579, $p$ = ,211 ; $F$(1, 117) = 3,108, $p$ = ,080), l'anthropomorphisme perçu ($F$(1, 117) = 0,108, $p$ = ,743), et la persuasion perçue ($F$(1, 117) = 0,444, $p$ = ,507). Une hétérogénéité des variances a été observée pour la confiance ($F$(1, 117) = 4,357, $p$ = ,039).

Les tests de Shapiro-Wilk ont révélé des déviations significatives de la normalité pour la confiance ($W$ = 0,949, $p$ < ,001), le score de production d'explication de la Phase 2 ($W$ = 0,91, $p$ < ,001), le test de connaissances post-interaction ($W$ = 0,97, $p$ = ,008), et la persuasion perçue ($W$ = 0,976, $p$ = ,032). L'anthropomorphisme perçu a démontré une normalité adéquate ($W$ = 0,985, $p$ = ,206). Par conséquent, des tests non-paramétriques (U de Mann-Whitney) ont été utilisés pour les variables violant les hypothèses de normalité, tandis que des tests paramétriques (tests t, ANOVA) ont été utilisés lorsque les hypothèses étaient satisfaites.

Pour l'analyse des mesures répétées de la compréhension auto-évaluée, le test de sphéricité de Mauchly a été conduit. L'hypothèse de sphéricité était satisfaite ($\chi^2$(2) = 5,52, $p$ = ,063), n'indiquant aucune violation de la sphéricité.


\subsection{Effets du Design de l'Agent}
\label{subsec:exp2-effets-design}

\textbf{Anthropomorphisme Perçu (Vérification de la Manipulation).} La Figure~\ref{fig:exp2_descriptives_anthropomorphism} présente la comparaison de l'anthropomorphisme perçu entre les conditions expérimentales. Un test t pour échantillons indépendants a examiné les différences d'anthropomorphisme perçu entre les conditions expérimentales. L'agent humanoïde ($M$ = 3,01, $ET$ = 0,83) n'a pas été perçu comme significativement plus anthropomorphique que l'agent abstrait ($M$ = 3,18, $ET$ = 0,81), $t$(117) = 1,127, $p$ = ,262, $d$ = 0,21, IC 95\% [-0,57, 0,15].

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{images/ch5/descriptives_anthropomorphism.png}
    \caption{Comparaison de l'anthropomorphisme perçu entre les conditions expérimentales. Les boîtes à moustaches montrent la médiane, les quartiles et les points de données individuels.}
    \label{fig:exp2_descriptives_anthropomorphism}
\end{figure}

\textbf{Confiance envers l'Agent (H1).} La Figure~\ref{fig:exp2_descriptives_trust} présente la comparaison de la confiance entre les conditions expérimentales. Étant donné la violation de l'homogénéité des variances et de la normalité pour cette variable, un test U de Mann-Whitney a été conduit. L'agent abstrait ($M$ = 4,86, $ET$ = 0,64) était associé à une confiance marginalement plus élevée comparé à l'agent humanoïde ($M$ = 4,59, $ET$ = 0,83), mais n'indiquait aucune différence significative, $U$ = 1502,50, $p$ = ,155, corrélation rang-bisériale = -0,151.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{images/ch5/descriptives_trust.png}
    \caption{Comparaison de la confiance entre les conditions expérimentales. Les boîtes à moustaches montrent la médiane, les quartiles et les points de données individuels.}
    \label{fig:exp2_descriptives_trust}
\end{figure}

\textbf{Persuasion Perçue (H2).} La Figure~\ref{fig:exp2_descriptives_persuasion} présente la comparaison de la persuasion perçue entre les conditions expérimentales. Un test U de Mann-Whitney a été conduit pour examiner les différences de persuasion perçue. Aucune différence significative n'a émergé entre l'agent humanoïde ($M$ = 3,84, $ET$ = 1,28) et l'agent abstrait ($M$ = 3,63, $ET$ = 1,20), $U$ = 1965,50, $p$ = ,300, corrélation rang-bisériale = 0,11.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{images/ch5/descriptives_persuasion.png}
    \caption{Comparaison de la persuasion perçue entre les conditions expérimentales. Les boîtes à moustaches montrent la médiane, les quartiles et les points de données individuels.}
    \label{fig:exp2_descriptives_persuasion}
\end{figure}

\textbf{Illusion de Profondeur Explicative (H3).} La Figure~\ref{fig:exp2_ioed_time} affiche l'évolution de la compréhension auto-évaluée à travers les trois points temporels pour les deux conditions expérimentales. Une ANOVA mixte à mesures répétées 2 (Condition : Humanoïde, Abstrait) $\times$ 3 (Temps : T1, T2, T3) a été conduite pour examiner les changements dans la compréhension auto-évaluée à travers les points temporels. L'analyse a révélé un effet principal significatif du Temps, $F$(2, 234) = 74,115, $p$ < ,001, $\eta_p^2$ = ,39, indiquant que la compréhension auto-évaluée a changé significativement à travers les points de mesure. L'interaction Temps $\times$ Condition n'était pas significative, $F$(2, 234) = 0,13, $p$ = ,878, $\eta_p^2$ < ,001. Par conséquent, l'effet inter-sujets de la Condition a été examiné et s'est révélé non significatif, $F$(1, 117) = 0,025, $p$ = ,875, $\eta_p^2$ < ,001.

Les comparaisons post-hoc par paires avec correction de Holm pour l'effet principal du Temps n'ont révélé aucune différence significative entre T1 (auto-évaluation initiale) et T2 (auto-évaluation post-explication), $t$(117) = 0,446, $p$ = ,656, $d$ = 0,03. Cependant, T3 (auto-évaluation post-interaction) était significativement plus élevé que T1, $t$(117) = 9,374, $p$ < ,001, $d$ = 0,69, et T2, $t$(117) = 11,572, $p$ < ,001, $d$ = 0,72. Ce pattern indique que la compréhension auto-évaluée a augmenté significativement après l'interaction avec l'agent, indépendamment du design de l'agent.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{images/ch5/ioed_time.png}
    \caption{Scores moyens de compréhension auto-évaluée (IOED) à travers trois points temporels (T1 : évaluation initiale, T2 : évaluation post-explication, T3 : évaluation post-interaction) pour les conditions agent humanoïde et agent abstrait. Les barres d'erreur représentent les erreurs standard.}
    \label{fig:exp2_ioed_time}
\end{figure}


\subsection{Mesures de Connaissances}
\label{subsec:exp2-mesures-connaissances}

\textbf{Score de Production d'Explication.} La Figure~\ref{fig:exp2_descriptives_explanation} présente la comparaison des scores de production d'explication entre les conditions. Un test U de Mann-Whitney n'a révélé aucune différence significative dans la qualité des explications produites pendant la Phase 2 du protocole IOED entre la condition agent humanoïde ($M$ = 5,92, $ET$ = 4,81) et la condition agent abstrait ($M$ = 5,32, $ET$ = 3,84), $U$ = 1857,00, $p$ = ,644, corrélation rang-bisériale = 0,05.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{images/ch5/descriptives_explanation.png}
    \caption{Comparaison des scores de production d'explication entre les conditions expérimentales. Les boîtes à moustaches montrent la médiane, les quartiles et les points de données individuels.}
    \label{fig:exp2_descriptives_explanation}
\end{figure}

\textbf{Test de Connaissances Post-Interaction.} La Figure~\ref{fig:exp2_descriptives_knowledge} présente la comparaison des scores au test de connaissances post-interaction entre les conditions. Un test U de Mann-Whitney n'a indiqué aucune différence significative entre la condition agent humanoïde ($M$ = 2,90, $ET$ = 1,71) et la condition agent abstrait ($M$ = 2,64, $ET$ = 1,57), $U$ = 1890,50, $p$ = ,517, corrélation rang-bisériale = 0,07.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{images/ch5/descriptives_knowledge.png}
    \caption{Comparaison des scores au test de connaissances post-interaction entre les conditions expérimentales. Les boîtes à moustaches montrent la médiane, les quartiles et les points de données individuels.}
    \label{fig:exp2_descriptives_knowledge}
\end{figure}


% =============================================================================
% SECTION 5.5 : DISCUSSION (ancienne 5.4)
% =============================================================================

\section{Discussion}
\label{sec:exp2_discussion}

Les résultats de cette étude présentent un tableau complexe de l'interaction entre les jeunes apprenants et les agents pédagogiques dont le discours est généré par l'intelligence artificielle. Contrairement à la plupart de nos hypothèses, nous n'avons observé aucune différence significative entre la condition humanoïde et la condition abstraite. Ce résultat nul, loin d'être une absence de découverte, constitue le point de départ d'une analyse plus approfondie. Il suggère que l'intégration des LLM dans les agents conversationnels a reconfiguré la hiérarchie des indices sociaux, où la fluidité du discours peut éclipser l'impact de l'incarnation visuelle. La discussion suivante vise à déconstruire ce phénomène en examinant chaque hypothèse à la lumière de nos résultats et de la littérature pertinente.

\subsection{Absence d'Effet sur la Confiance et la Persuasion}
\label{subsec:exp2_discussion_trust_persuasion}

Contrairement à notre première hypothèse (H1), qui prédisait que l'agent humanoïde susciterait une confiance plus élevée, les résultats n'ont révélé aucune différence significative entre les deux conditions sur cette mesure (Figure~\ref{fig:exp2_descriptives_trust}). De même, contrairement à notre seconde hypothèse (H2), aucune différence significative n'a été observée concernant la persuasion perçue (Figure~\ref{fig:exp2_descriptives_persuasion}).

De manière également inattendue, l'agent humanoïde n'a pas été perçu comme significativement plus anthropomorphe que l'agent abstrait (Figure~\ref{fig:exp2_descriptives_anthropomorphism}). Bien que cette différence ait été conçue comme une vérification de la manipulation plutôt qu'une hypothèse formelle, son absence constitue un résultat notable. L'analyse des retours qualitatifs des élèves suggère que ce résultat nul ne provient pas d'une absence d'effet de la forme, mais plutôt d'un équilibre de défauts : chaque agent a échoué à être perçu comme supérieur, mais pour des raisons spécifiques à sa nature.

L'agent humanoïde a souffert d'une dissonance comportementale. La qualité de sa représentation visuelle statique était néanmoins une réussite, comme en ont témoigné les élèves : « Sans que le personnage parle ou bouge, j'aurais pensé que c'était une vraie personne sur une photo par exemple », au point de semer le doute sur sa nature artificielle (« J'ai eu des doutes, je pensais que c'était un humain »). Cette crédibilité visuelle initiale a établi un « contrat de cohérence » implicite, créant des attentes très élevées concernant son comportement. Cependant, ce contrat a été rompu dès que l'agent s'est animé. Des imperfections subtiles --- « il faisait les mêmes gestes tout le temps », « seule la bouche bouge mais pas le reste du visage » --- ont constitué une violation de ces attentes qui a généré un sentiment d'étrangeté \citep{groom2009, burgoon2015}. Ce phénomène, où un réalisme visuel élevé non accompagné d'un réalisme comportemental équivalent dégrade la crédibilité, a été documenté dans des études antérieures \citep{bengtsson1999, nowak2004} et persiste aujourd'hui \citep{haresamudram2024}. Bien que les agents synthétiques modernes puissent éviter l'effet de vallée de l'étrange \citep{xu2025a}, notre stimulus a clairement franchi un seuil d'incohérence multimodale qui a annulé les bénéfices sociaux attendus de son incarnation.

À l'inverse, l'agent abstrait a été pénalisé par une « perfection suspecte ». En l'absence de visage pour ancrer l'évaluation, les élèves se sont concentrés exclusivement sur les caractéristiques du discours. Leur retour, « Normalement quand on parle on a des moments de réflexion », est révélateur. Ils ont mobilisé une heuristique implicite de « travail cognitif », associant l'intelligence à des marqueurs de réflexion. La fluidité parfaite de l'agent n'a pas été interprétée comme un signe d'intelligence supérieure, mais comme la preuve d'un simple script préenregistré (« Ce n'était pas vraiment une IA, c'était une voix récitant un texte »). Cette perfection a signalé son artificialité et diminué son agentivité perçue. Pour les jeunes apprenants, les indices paralinguistiques sont des déterminants critiques pour l'attribution d'agentivité \citep{xu2025}. La performance impeccable de l'agent abstrait a ainsi paradoxalement sapé sa crédibilité en tant que « tuteur » intelligent.

Ces deux échecs symétriques ont été interprétés par des élèves agissant comme des évaluateurs actifs \citep{oh2025}. Informés de la nature IA, et reconnaissant même la technologie sous-jacente (« C'est ChatGPT ! »), ils ont jugé les agents selon des schémas préexistants concernant les capacités de l'IA plutôt que sur de simples indices visuels. Cette identification préalable a peut-être établi un niveau de confiance de base élevé, mais aussi une plus grande sensibilité aux défauts. La confiance envers la technologie est contextuelle ; elle dépend de sa fiabilité passée \citep{danovitch2013} et de son adéquation perçue pour une tâche \citep{girouard-hallam2025}. Dans notre cas, en l'absence de familiarité personnelle qui aurait pu orienter la confiance \citep{tan2025}, les deux agents ont été jugés fonctionnellement équivalents, confirmant que les attentes des adolescents mûrissent plus rapidement que ne le suggérait la littérature antérieure \citep{Nguyen2022}. Ils ne sont plus impressionnés par la simple capacité d'une machine à parler, et sont devenus des juges exigeants de la cohérence et de l'authenticité perçues des agents virtuels.

\subsection{L'Illusion de Compréhension}
\label{subsec:exp2_discussion_illusion}

Notre troisième hypothèse (H3), qui prédisait qu'un agent humanoïde induirait une illusion de compréhension plus forte, n'a pas été confirmée par les données. En revanche, l'analyse révèle un phénomène plus fondamental et uniforme qui a transcendé nos conditions expérimentales. Dans les deux groupes, nous avons observé une augmentation significative de l'auto-évaluation de la compréhension entre le moment où les élèves ont tenté d'expliquer le processus eux-mêmes (T2) et le moment suivant leur interaction avec l'agent (T3) (Figure~\ref{fig:exp2_ioed_time}). Le point critique est que cette hausse de confiance s'est produite alors que l'agent n'avait fourni aucune nouvelle information sur le sujet spécifique de l'évaluation --- la momification. Cet écart entre le contenu reçu et la confiance gagnée met en évidence la formation d'un « halo de confiance ».

L'effet de halo --- introduit initialement par \citet{thorndike1920} et récemment synthétisé dans le contexte des biais liés à l'IA \citep{campbell2025} --- décrit un biais cognitif où « un attribut positif d'une personne influence les perceptions de ses autres traits non liés ». Dans notre contexte, les résultats suggèrent que les élèves ont pu généraliser la compétence perçue de l'agent sur des sujets périphériques (fluidité, clarté sur des anecdotes) à l'ensemble du domaine de connaissances.

Une explication plausible de cet effet pourrait résider non pas dans l'apparence de l'agent, mais dans la performance multimodale de son discours, qui semble avoir été portée par deux facteurs de fluence agissant en synergie. Le premier facteur, de nature linguistique, est la qualité du contenu généré par le LLM. Comme les élèves l'ont verbalisé, l'agent était « super clair et [...] très confiant ». Cette performance s'aligne avec la théorie de la « fluence de l'instructeur », un biais où les apprenants peuvent interpréter à tort la clarté d'un enseignant comme un indicateur de leur propre apprentissage \citep{toftness2018, wilson2018}. En maximisant la « fluence de traitement » \citep{reber1999}, le discours a pu rendre l'information facile à assimiler, créant une forte impression de compétence perçue.

Le second facteur, de nature auditive, est la qualité de la voix synthétique. La voix peut en effet agir comme un vecteur d'humanisation \citep{schroeder2016}. La recherche antérieure a établi que la qualité prosodique de la voix est souvent un facteur plus déterminant que l'apparence visuelle pour la perception du naturel \citep{ehret2021}. Cependant, nos résultats mettent en lumière une tension dans cette dynamique. Nous proposons que cette interaction puisse être interprétée à travers le prisme de la théorie du double processus \citep{kahneman2013}. Tandis que la fluence prosodique de la voix réduit la charge cognitive et favorise probablement une illusion immédiate de compréhension (traitement heuristique du Système 1 : « C'est clair, donc je comprends »), son absence de disfluences naturelles (par exemple, hésitations, respirations) peut signaler l'artificialité lors d'une réflexion plus approfondie (traitement analytique du Système 2 : « C'est trop parfait pour être humain »), déclenchant potentiellement un sentiment de dissonance qui entrave une confiance relationnelle plus profonde.

La combinaison de ces deux fluences --- un texte parfaitement structuré et une voix prosodiquement convaincante --- a pu créer une performance perçue si crédible qu'elle a activé chez les élèves un schéma social d'expertise, comme en témoignent leurs remarques comparant l'agent à « un vrai professeur d'Histoire » qui « connaissait très bien son sujet ».

Cette double fluence, linguistique et auditive, pourrait avoir des conséquences sur l'engagement cognitif. Elle survient dans une interaction conversationnelle, un mode de présentation qui tend à augmenter la crédibilité perçue et à réduire la détection des inexactitudes par rapport au texte statique, car il peut activer des heuristiques sociales qui diminuent la vigilance critique \citep{anderl2024}. Même lorsque le contenu n'est pas jugé plus crédible dans l'ensemble, il est souvent perçu comme plus clair et plus engageant, une qualité qui pourrait conduire à une acceptation non critique \citep{huschens2023}. Cet écart entre la confiance subjective et l'apprentissage réel pourrait ne pas ressembler à une simple erreur de jugement passive. Il pourrait être une conséquence de la nature même de l'interaction avec un agent génératif, qui pourrait promouvoir une forme de « paresse métacognitive » \citep{fan2023}. Confrontés à une source qui fournit des réponses instantanées et fluides, les apprenants pourraient être enclins à déléguer les processus cognitifs les plus coûteux.

Cette tendance est soutenue par le « paradoxe métacognitif » : bien que l'assistance de l'IA puisse améliorer la performance, elle pourrait simultanément dégrader la capacité de l'utilisateur à évaluer cette même performance, conduisant à une surconfiance \citep{fernandes2026}. De même, les utilisateurs tendent à surestimer la précision des modèles d'IA sur la base de la confiance apparente des explications fournies, un écart de calibration qui ne se réduit que lorsque le style de l'IA communique explicitement son niveau de confiance en utilisant des phrases spécifiques (par exemple, « Je ne suis pas sûr » ou « Je suis confiant ») \citep{steyvers2025}. En rendant la tâche d'apprentissage apparemment plus facile, l'agent pourrait priver les élèves des « difficultés souhaitables » --- l'effort de construction et de réorganisation des connaissances --- qui sont pourtant considérées comme essentielles pour un apprentissage durable \citep{bjork2013}. La réduction de l'effort mental observée lors de l'utilisation des LLM se traduit ainsi par un déclin de la qualité de l'apprentissage conceptuel \citep{stadler2024}. Dans cette perspective, la confiance retrouvée à T3 pourrait être interprétée non comme le fruit de connaissances nouvellement acquises, mais comme le symptôme d'un effort cognitif externalisé, dont l'apprenant ne serait pas pleinement conscient.

\subsection{Mesures de Connaissances}
\label{subsec:exp2_discussion_knowledge}

Les résultats confirment l'absence de différence significative entre les conditions sur la qualité des explications initiales (Figure~\ref{fig:exp2_descriptives_explanation}) et les scores au test post-interaction (Figure~\ref{fig:exp2_descriptives_knowledge}). Ce résultat nul est cohérent avec le protocole : l'agent n'a fourni aucune information factuelle qui était évaluée. Cependant, cette stabilité de la performance objective contraste avec l'augmentation de la confiance subjective (IOED T3). Les élèves se sentent plus compétents sans avoir amélioré leurs connaissances : c'est précisément cette dissociation qui caractérise l'illusion de compréhension observée.

Ce phénomène peut s'expliquer par le rôle de l'interaction elle-même. Les agents --- qu'ils soient humanoïdes (distracteurs sociaux, \citealt{li2024}) ou abstraits (distracteurs perceptuels potentiels) --- ne détournent pas simplement l'attention. Ils créent une expérience d'interaction fluide qui réduit le sentiment d'effort cognitif nécessaire. Cette facilité perçue favorise une posture métacognitive passive, en ligne avec la théorie des détails séduisants \citep{wilson2018}.

\subsection{Implications Théoriques et Pratiques}
\label{subsec:exp2_discussion_implications}

Les résultats de cette étude ont des implications significatives. Sur le plan théorique, ils invitent à réévaluer le paradigme CASA \citep{nass1994} et le principe d'incarnation \citep{fiorella2021} à l'ère des agents génératifs. La fluidité conversationnelle émerge comme un signal social de premier ordre, capable de dominer les effets de l'apparence visuelle. L'effet d'incarnation semble conditionné par un seuil de réalisme comportemental que les technologies actuelles peinent à atteindre. De manière plus critique, nos résultats démontrent que cette fluidité crée une forte illusion de compréhension, caractérisée par une auto-évaluation gonflée sans gains objectifs \citep{paik2013}. Bien que ce biais métacognitif soit problématique en soi, car il arrête prématurément le processus d'apprentissage, ses implications deviennent alarmantes lorsqu'elles sont contextualisées dans les limites inhérentes de l'IA générative. Dans notre protocole contrôlé, l'agent fournissait des informations factuellement exactes. Cependant, dans des scénarios réels, les LLM sont sujets aux « hallucinations » --- la génération d'informations plausibles mais incorrectes présentées avec une grande confiance \citep{zhang2025, shanahan2024}.

Cela connecte nos résultats sur l'illusion métacognitive au phénomène distinct de surconfiance épistémique décrit par \citet{kulgemeyer2023}. Ils ont montré que les apprenants acceptent facilement des explications scientifiquement erronées lorsqu'elles sont intuitives et présentées de manière fluide. Notre étude suggère un mécanisme pour cette vulnérabilité : parce que la fluidité de l'IA rend la tâche d'apprentissage facile --- ce que \citet{fernandes2026} décrivent comme un « paradoxe métacognitif » --- les apprenants désactivent leur vigilance critique. Par conséquent, ils deviennent susceptibles à l'« effet de vérité illusoire » \citep{fazio2015}, où la simple répétition et la présentation fluide d'une déclaration peuvent supplanter les connaissances antérieures. Si les apprenants ne peuvent pas distinguer entre « avoir l'impression de comprendre » et « savoir réellement » lorsque le contenu est correct, comme observé dans notre étude, ils sont peu susceptibles de détecter le « discours négligent » d'une IA hallucinante \citep{wachter2024}. Des recherches récentes confirment ce danger, montrant que les explications IA trompeuses peuvent être encore plus persuasives que les explications honnêtes \citep{danry2024} et que les utilisateurs accordent leur confiance aux réponses médicales de l'IA malgré une faible précision \citep{shekar2024}. Par conséquent, le « halo de confiance » que nous avons observé --- où les élèves ont généralisé la compétence perçue de l'agent à l'ensemble du domaine --- agit comme un bouclier de crédibilité.

Sur le plan pratique, ces conclusions appellent à un changement de philosophie dans la conception des agents pédagogiques. La tendance actuelle vise à créer des outils « transparents » qui s'effacent pour laisser place à la tâche. En terminologie heideggérienne \citep{heidegger2016}, un agent génératif est conçu pour être un outil parfaitement \textit{zuhanden} (« sous-la-main »), un marteau cognitif qui s'intègre si fluidement dans l'action qu'il devient invisible. Or, c'est précisément cette invisibilité qui encourage la paresse métacognitive. L'outil ne devient un objet de réflexion --- \textit{vorhanden} (« présent-à-portée-de-main ») --- que lorsqu'il se brise ou révèle un défaut. Nos résultats qualitatifs montrent que les élèves ont précisément été confrontés à ces « ruptures » : la dissonance comportementale de l'agent humanoïde et la perfection suspecte de l'agent abstrait sont les « bugs » qui ont rendu l'outil visible et forcé une évaluation critique de sa nature.

L'implication paradoxale est que, à des fins pédagogiques, l'objectif ne devrait pas être de créer un outil encore plus parfait et invisible, mais de « scripter la rupture ». Au lieu de maximiser la confiance, il faut la calibrer en exposant délibérément les limites de l'agent. Cela signifie concevoir des tuteurs IA qui, loin de fournir des réponses directes et fluides, rendent visible leur processus de « réflexion », admettent leur incertitude, ou forcent l'apprenant à valider l'information. Il s'agit de transformer l'agent d'une « boîte noire » en un « partenaire de discussion ». Exposer délibérément les apprenants aux limites de l'IA s'est révélé être une stratégie efficace pour modérer la surconfiance et développer une littératie numérique adaptée aux défis de demain \citep{solyst2024}.

\subsection{Limites et Perspectives de Recherche}
\label{subsec:exp2_discussion_limitations}

Bien que cette étude éclaire la perception des agents génératifs par les jeunes apprenants, ses conclusions doivent être considérées à la lumière de plusieurs limites qui définissent la portée de leur validité et tracent des pistes pour de futures investigations.

Une limitation fondamentale concerne la nature de l'interaction. Pour assurer un contrôle expérimental rigoureux, les réponses de l'agent ont été pré-générées par un LLM puis validées, et non produites en temps réel. Notre étude a ainsi mesuré la réaction des élèves à un discours parfaitement fluide et correct, simulant un agent idéal, sans exposer les participants aux caractéristiques de l'interaction directe : latence, variabilité des réponses, ou risque d'hallucinations \citep{zhang2025}. Les recherches futures devront répliquer ce type d'étude avec un agent interactif en temps réel, pour observer comment la confiance évolue face à la performance réelle d'un système stochastique \citep{shanahan2024}.

Deuxièmement, la tâche assignée était très structurée, limitée à poser des questions prédéfinies et à écouter passivement. Ce cadre ne reflète pas la complexité des usages réels impliquant la co-création, la résolution de problèmes ou la recherche ouverte. Des études montrent que même des étudiants universitaires avertis peinent à maintenir leur vigilance critique lors de tâches d'écriture \citep{church2024}. Il serait pertinent d'explorer ces dynamiques dans des scénarios d'apprentissage par projet, où l'agent devient un outil à mobiliser plutôt qu'une source à consommer, pour identifier des stratégies de lutte contre la paresse métacognitive \citep{fan2023}.

Troisièmement, nos stimuli visuels ne représentent qu'un échantillon limité des designs possibles. Les résultats pourraient différer en variant le genre, l'âge perçu ou l'ethnicité, vecteurs connus de biais dans l'interaction homme-machine \citep{nass1997}. Les recherches futures pourraient explorer un continuum d'anthropomorphisme, tester des agents cartoon ou non humains \citep{zanbaka2006}, et découpler les effets de la voix et de l'apparence, qui étaient maintenus constants dans notre étude, pour mieux comprendre leur contribution respective à la construction de la confiance \citep{chiou2020}.

Finalement, nos mesures reposaient sur des échelles auto-rapportées qui ne capturent que la perception subjective, pas le comportement réel. La littérature établit une dissociation entre la confiance déclarée et la confiance comportementale \citep{kulms2019}. Les études futures pourraient intégrer des mesures comportementales, où les élèves prennent des décisions avec des conséquences concrètes, pour vérifier si le « halo de confiance » observé se traduit en surconfiance comportementale.

Ces limites esquissent une perspective centrée sur la calibration de la confiance. S'appuyant sur notre conclusion que les « bugs » perceptuels rendent l'outil visible et suscitent une évaluation critique, les études futures pourraient tester des agents délibérément « imparfaits » admettant leurs limites \citep{sderlund2024} ou introduire des erreurs contrôlées. L'étude empirique de l'efficacité des « ruptures scriptées » représente une piste de recherche prometteuse. Celles-ci pourraient constituer un remède pédagogique efficace contre l'illusion de compréhension et la paresse métacognitive.

\subsection{Synthèse}
\label{subsec:exp2_discussion_synthesis}

Cette étude a examiné l'influence du design visuel d'un agent conversationnel alimenté par l'intelligence artificielle générative sur la confiance, la persuasion et l'illusion de compréhension chez les jeunes adolescents. Contrairement aux prédictions initiales basées sur le paradigme CASA et la théorie de l'agentivité sociale, l'apparence humanoïde n'a pas suscité une confiance ou un engagement plus importants que l'agent abstrait. Cependant, les deux conditions ont induit une augmentation significative de l'auto-évaluation de la compréhension par les élèves, sans amélioration correspondante de leur performance objective.

Ces résultats suggèrent une possible reconfiguration de la hiérarchie des indices sociaux dans l'interaction homme-machine à l'ère des grands modèles de langage. La fluidité conversationnelle et la qualité prosodique de la parole --- bien qu'elles puissent potentiellement signaler l'artificialité lors d'une réflexion approfondie --- fonctionnent principalement comme de puissantes heuristiques cognitives qui facilitent le traitement de l'information, supplantant ainsi les effets de l'incarnation visuelle sur les jugements métacognitifs. Cette prédominance apparente de la fluence verbale génère un risque pédagogique majeur : une « illusion de maîtrise » métacognitive. En facilitant le traitement de l'information, l'agent IA, quelle que soit son apparence, semble capable de conduire les apprenants à confondre la clarté de la présentation avec leur propre compétence, favorisant ainsi une passivité cognitive.

Cette dissociation entre confiance subjective et connaissances réelles est particulièrement critique étant donné la propension des modèles génératifs aux hallucinations. Si les apprenants réduisent leur vigilance critique face à un contenu correct en raison de sa fluidité, comme observé ici, ils deviennent vulnérables à accepter des informations erronées présentées avec la même assurance. Par conséquent, le défi pour la conception des technologies éducatives ne réside plus nécessairement dans la poursuite d'un réalisme anthropomorphique maximal, ni dans la création d'interfaces « transparentes ». Au contraire, pour contrer la paresse métacognitive et calibrer la confiance, il apparaît nécessaire de concevoir des agents qui rendent leurs limites perceptibles. Les recherches futures devront explorer l'efficacité des « ruptures scriptées » --- des mécanismes de conception qui brisent délibérément la fluidité pour réengager les processus de surveillance de l'apprenant --- afin de tenter de transformer l'interaction avec l'IA en un véritable partenariat critique plutôt qu'en une consommation passive d'informations.
