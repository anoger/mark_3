\section{L'émergence des IA génératives en éducation}
\label{sec:ia_generatives}

\subsection{Des agents scriptés aux agents génératifs : le saut qualitatif}
\label{subsec:agents_scriptes_generatifs}

Les agents pédagogiques classiques fonctionnent selon une logique de scripts prédéfinis. L'apprenant pose une question ; le système la compare à une base de patterns ; il sélectionne une réponse dans un arbre de décision. Cette architecture impose deux contraintes. La couverture dépend du nombre de cas anticipés par les concepteurs. La contingence conversationnelle reste superficielle, car l'agent ne construit pas sa réponse à partir du contenu sémantique de l'échange. Les revues systématiques confirment ce diagnostic : les agents scriptés produisent des effets positifs mais modestes, et leur efficacité décroît avec la durée d'interaction \citep{schroeder2025, veletsianos2013}. L'apprenant détecte progressivement l'absence de véritable adaptation, ce qui érode la présence sociale (cf.~\ref{subsec:incarnation_agence_sociale}).

Les grands modèles de langage (LLM, \textit{Large Language Models}) reposent sur une architecture radicalement différente. Un LLM est un réseau de neurones entraîné sur des corpus massifs de textes à prédire le mot suivant d'une séquence. L'entraînement ajuste des milliards de paramètres pour capturer les régularités statistiques du langage. Le modèle n'apprend pas des règles explicites : il apprend des distributions de probabilités sur des séquences de tokens. À l'inférence, le modèle génère du texte token par token, chaque prédiction conditionnée par le contexte précédent. Cette génération autoregressive produit un discours fluide et cohérent sans recourir à des scripts prédéfinis \citep{vaswani2017, brown2020}.

Cette architecture confère aux LLM une propriété centrale : la génération contextuelle. Le modèle produit des réponses adaptées au contenu spécifique de l'échange, non sélectionnées dans un répertoire fixe. De cette propriété découlent deux capacités dérivées. La flexibilité stylistique permet d'ajuster le registre, le niveau de détail et le ton en fonction du profil inféré de l'utilisateur. La capacité de raisonnement apparent permet de décomposer des problèmes et d'expliquer des étapes de raisonnement \citep{wei2022}. Ces capacités convergent vers un même effet : une adaptation en temps réel qui positionne les LLM comme des outils prometteurs pour l'accompagnement pédagogique \citep{pataranutaporn2021, yan2024}.

Ces capacités trouvent des applications dans l'enseignement de l'histoire, un domaine où la narration et le dialogue avec des figures du passé présentent un potentiel pédagogique spécifique. Des plateformes expérimentales intègrent désormais des personnages non-joueurs génératifs dans des simulations historiques \citep{park2025}, tandis que d'autres exploitent l'ingénierie de prompt comme activité d'apprentissage à part entière \citep{lim2025}. Ces prototypes démontrent la faisabilité technique de l'approche. Leur évaluation reste cependant limitée : échantillons restreints, mesures principalement perceptuelles, absence de suivi longitudinal. La question de l'efficacité pédagogique réelle demeure ouverte.

L'évolution des médias synthétiques amplifie cette transformation. Les réseaux antagonistes génératifs (GANs) et les modèles de diffusion permettent de créer des visages photoréalistes, de cloner des voix et de générer des animations faciales synchronisées avec la parole \citep{whittaker2020}. Un instructeur virtuel peut désormais présenter une apparence humaine convaincante et une voix indiscernable d'un enregistrement réel. Ces agents hyperréalistes évitent la vallée de l'étrange et sont perçus comme attractifs \citep{xu2025a}. Cette attractivité n'est pas neutre : elle peut favoriser l'engagement, mais aussi réduire la distance critique que l'apprenant maintient face à une source d'information. La fluence comportementale des LLM --- leur capacité à maintenir une conversation naturelle --- soutient des niveaux de réalisme visuel que les systèmes scriptés ne pouvaient pas accompagner.

La convergence de ces deux avancées --- génération de langage naturel et synthèse médiatique --- produit une nouvelle équation. D'un côté, un moteur conversationnel capable de générer un discours parfaitement articulé. De l'autre, une interface visuelle hyperréaliste pour l'incarner. Cette combinaison permet de créer des agents qui maintiennent la présence sociale au-delà des premières minutes d'interaction, précisément parce qu'ils produisent des réponses contextuellement pertinentes plutôt que des sélections dans un catalogue. La co-construction au sens du cadre ICAP (cf.~\ref{subsec:icap}) devient techniquement possible : chaque contribution de l'agent peut s'appuyer sur la précédente et la transformer.

Cette avancée ouvre de nouvelles possibilités pédagogiques. Les agents génératifs peuvent fournir un feedback individualisé, adapter leurs explications au niveau de l'apprenant et maintenir un dialogue soutenu sur des sujets complexes. Certaines études rapportent des performances d'apprentissage comparables à celles obtenues avec des instructeurs humains \citep{leiker2023, lim2024}. Cette comparabilité mérite cependant d'être interrogée : elle repose sur des mesures immédiates, des échantillons restreints et des contextes expérimentaux qui limitent la généralisation. L'intégration de techniques de récupération augmentée (RAG, \textit{Retrieval-Augmented Generation}) permet d'ancrer les réponses dans des sources vérifiées, réduisant partiellement le risque d'erreurs factuelles \citep{lewis2020}.

Cette capacité nouvelle introduit simultanément des risques inédits. La fluence linguistique des LLM ne garantit pas l'exactitude de leur contenu. La section suivante examine comment cette fluence peut servir la personnalisation de l'apprentissage, avant d'aborder le défi épistémique que posent les hallucinations.

