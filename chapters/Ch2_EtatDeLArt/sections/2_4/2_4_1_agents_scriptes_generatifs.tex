\subsection{Des agents scriptés aux agents génératifs : le saut qualitatif}
\label{subsec:agents_scriptes_generatifs}

Le plafond structurel des agents scriptés --- rigidité des réponses, érosion de la présence sociale, absence de contingence sémantique (cf.~\ref{subsec:incarnation_agence_sociale}) --- motive la recherche de systèmes capables d'adaptation. Les effets positifs mais modestes rapportés par les revues systématiques tendent à décroître avec la durée d'interaction, l'apprenant percevant progressivement l'absence de véritable adaptation \citep{schroeder2025, veletsianos2013}. Les chatbots dotés de capacités d'IA conversationnelle commencent à dépasser ces contraintes, avec des effets positifs sur l'apprentissage et l'engagement \citep{wu2024ai}. Les agents dotés de technologies d'IA tendent à produire des effets plus favorables que les agents scriptés, et la durée de l'intervention module les résultats : les sessions courtes ($\leq$~30~min) et longues ($\geq$~120~min) produisent des effets plus marqués que les durées intermédiaires, un profil qui suggère à la fois un effet de nouveauté et la nécessité d'une exposition prolongée pour installer la relation avec l'agent \citep{dai2024-gv}. Les grands modèles de langage (LLM, \textit{Large Language Models}) reposent sur une architecture différente. Un LLM est un réseau de neurones entraîné sur des corpus massifs de textes à prédire le mot suivant d'une séquence. L'entraînement ajuste des milliards de paramètres pour capturer les régularités statistiques du langage : le modèle apprend des distributions de probabilités sur des séquences de tokens, non des règles explicites. À l'inférence, la génération autoregressive --- chaque prédiction conditionnée par le contexte précédent --- produit un discours fluide et cohérent sans recourir à des scripts prédéfinis \citep{vaswani2017, brown2020}. De cette architecture découle une propriété centrale : la génération contextuelle.

La génération contextuelle signifie que le modèle produit des réponses adaptées au contenu spécifique de l'échange, non sélectionnées dans un répertoire fixe. De cette propriété découlent deux capacités dérivées. La flexibilité stylistique permet d'ajuster le registre, le niveau de détail et le ton en fonction du profil inféré de l'utilisateur. La capacité de raisonnement apparent permet de décomposer des problèmes et d'expliquer des étapes de résolution \citep{wei2023}. Ces capacités convergent vers une adaptation en temps réel qui distingue les LLM des systèmes antérieurs dans l'accompagnement pédagogique \citep{pataranutaporn2021, yan2024}. L'enseignement de l'histoire constitue un domaine d'application où ces capacités trouvent un terrain spécifique : la narration, le dialogue avec des figures du passé et l'interprétation de sources primaires mobilisent une compétence langagière que les agents scriptés ne pouvaient pas soutenir. Des plateformes expérimentales intègrent désormais des personnages non-joueurs génératifs dans des simulations historiques \citep{park2025}, tandis que d'autres exploitent l'ingénierie de prompt comme activité d'apprentissage à part entière \citep{lim2025}. Ces prototypes démontrent la faisabilité technique de l'approche, mais leur évaluation reste limitée : échantillons restreints, mesures principalement perceptuelles, absence de suivi longitudinal.

L'évolution des médias synthétiques amplifie cette transformation. Les réseaux antagonistes génératifs (GANs) et les modèles de diffusion, documentés dès le début de la décennie \citep{whittaker2020}, permettent désormais de créer des visages photoréalistes, de cloner des voix et de générer des animations faciales synchronisées avec la parole. Un instructeur virtuel peut présenter une apparence humaine convaincante et une voix indiscernable d'un enregistrement réel. Ces agents hyperréalistes semblent franchir la zone d'inconfort décrite en~\ref{subsec:uncanny_valley} et sont perçus comme attractifs \citep{xu2025a}. Cette attractivité n'est pas neutre : elle peut favoriser l'engagement, mais aussi réduire la distance critique que l'apprenant maintient face à une source d'information. L'aisance conversationnelle des LLM --- leur capacité à maintenir un échange naturel --- soutient des niveaux de réalisme visuel que les systèmes scriptés ne pouvaient pas accompagner.

La co-construction au sens du cadre ICAP (cf.~\ref{subsec:icap}) devient techniquement possible : chaque contribution de l'agent peut s'appuyer sur la précédente et la transformer, précisément parce que la réponse est générée à partir du contexte de l'échange plutôt que sélectionnée dans un catalogue. Les agents génératifs peuvent fournir un feedback individualisé, adapter leurs explications au niveau de l'apprenant et maintenir un dialogue soutenu sur des sujets complexes. Un agent conversationnel qui signale ce que l'enfant ne sait pas encore suscite des questions plus divergentes et une exploration plus autonome \citep{abdelghani2022-mk}.

Les preuves concernant les résultats d'apprentissage objectifs restent cependant fragiles. L'aisance verbale des LLM ne garantit pas l'exactitude de leur contenu. La capacité d'adaptation décrite dans cette section modifie l'expérience de l'apprenant, mais la nature exacte de cette modification --- sur la perception, sur l'apprentissage, sur la confiance accordée au contenu --- reste largement ouverte.

